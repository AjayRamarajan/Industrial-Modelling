{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8JvUcK2qmaz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from scipy import stats\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.stats import norm, skew\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/Copper_Set.csv\")\n",
        "df.head()\n",
        "\n",
        "<ipython-input-23-af65ff6af436>:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv(\"/content/Copper_Set.csv\")\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tmaterial_ref\tproduct_ref\tdelivery date\tselling_price\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.00\t1500.0\tDEQ1 S460MC\t1670798778\t20210701.0\t854.00\n",
        "1\t4E5F4B3D-DDDF-499D-AFDE-A3227EC49425\t20210401.0\t768.024839\t30202938.0\t25.0\tWon\tW\t41.0\t0.80\t1210.0\t0000000000000000000000000000000000104991\t1668701718\t20210401.0\t1047.00\n",
        "2\tE140FF1B-2407-4C02-A0DD-780A093B1158\t20210401.0\t386.127949\t30153963.0\t30.0\tWon\tWI\t28.0\t0.38\t952.0\tS0380700\t628377\t20210101.0\t644.33\n",
        "3\tF8D507A0-9C62-4EFE-831E-33E1DA53BB50\t20210401.0\t202.411065\t30349574.0\t32.0\tWon\tS\t59.0\t2.30\t1317.0\tDX51D+ZM310MAO 2.3X1317\t1668701718\t20210101.0\t768.00\n",
        "4\t4E1C4E78-152B-430A-8094-ADD889C9D0AD\t20210401.0\t785.526262\t30211560.0\t28.0\tWon\tW\t10.0\t4.00\t2000.0\t2_S275JR+AR-CL1\t640665\t20210301.0\t577.00\n",
        "\n",
        "df.shape\n",
        "\n",
        "(181673, 14)\n",
        "\n",
        "df.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 181673 entries, 0 to 181672\n",
        "Data columns (total 14 columns):\n",
        " #   Column         Non-Null Count   Dtype\n",
        "---  ------         --------------   -----\n",
        " 0   id             181671 non-null  object\n",
        " 1   item_date      181672 non-null  float64\n",
        " 2   quantity tons  181673 non-null  object\n",
        " 3   customer       181672 non-null  float64\n",
        " 4   country        181645 non-null  float64\n",
        " 5   status         181671 non-null  object\n",
        " 6   item type      181673 non-null  object\n",
        " 7   application    181649 non-null  float64\n",
        " 8   thickness      181672 non-null  float64\n",
        " 9   width          181673 non-null  float64\n",
        " 10  material_ref   103754 non-null  object\n",
        " 11  product_ref    181673 non-null  int64\n",
        " 12  delivery date  181672 non-null  float64\n",
        " 13  selling_price  181672 non-null  float64\n",
        "dtypes: float64(8), int64(1), object(5)\n",
        "memory usage: 19.4+ MB\n",
        "\n",
        "df.duplicated().sum()\n",
        "\n",
        "0\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "0\n",
        "id\t2\n",
        "item_date\t1\n",
        "quantity tons\t0\n",
        "customer\t1\n",
        "country\t28\n",
        "status\t2\n",
        "item type\t0\n",
        "application\t24\n",
        "thickness\t1\n",
        "width\t0\n",
        "material_ref\t77919\n",
        "product_ref\t0\n",
        "delivery date\t1\n",
        "selling_price\t1\n",
        "\n",
        "dtype: int64\n",
        "\n",
        "df.columns\n",
        "\n",
        "Index(['id', 'item_date', 'quantity tons', 'customer', 'country', 'status',\n",
        "       'item type', 'application', 'thickness', 'width', 'material_ref',\n",
        "       'product_ref', 'delivery date', 'selling_price'],\n",
        "      dtype='object')\n",
        "\n",
        "# formating date columns from float to date\n",
        "df['item_date']=pd.to_datetime(df['item_date'],format='%Y%m%d',errors='coerce').dt.date\n",
        "df['delivery date']=pd.to_datetime(df['delivery date'],format='%Y%m%d',errors='coerce').dt.date\n",
        "\n",
        "# converting dtype date columns to datatime\n",
        "df['item_date']=pd.to_datetime(df['item_date'])\n",
        "df['delivery date']=pd.to_datetime(df['delivery date'])\n",
        "\n",
        "\n",
        "# Calculating time taken to delivery in days\n",
        "df['delivery_time_taken']=(df['item_date']-df['delivery date']).abs().dt.days\n",
        "\n",
        "\n",
        "# converting values in the quantity tons to float\n",
        "df['quantity tons']=pd.to_numeric(df['quantity tons'],errors='coerce')\n",
        "\n",
        "\n",
        "df.head(1)\n",
        "\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tmaterial_ref\tproduct_ref\tdelivery date\tselling_price\tdelivery_time_taken\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t2021-04-01\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\tDEQ1 S460MC\t1670798778\t2021-07-01\t854.0\t91.0\n",
        "\n",
        "df.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 181673 entries, 0 to 181672\n",
        "Data columns (total 15 columns):\n",
        " #   Column               Non-Null Count   Dtype\n",
        "---  ------               --------------   -----\n",
        " 0   id                   181671 non-null  object\n",
        " 1   item_date            181670 non-null  datetime64[ns]\n",
        " 2   quantity tons        181672 non-null  float64\n",
        " 3   customer             181672 non-null  float64\n",
        " 4   country              181645 non-null  float64\n",
        " 5   status               181671 non-null  object\n",
        " 6   item type            181673 non-null  object\n",
        " 7   application          181649 non-null  float64\n",
        " 8   thickness            181672 non-null  float64\n",
        " 9   width                181673 non-null  float64\n",
        " 10  material_ref         103754 non-null  object\n",
        " 11  product_ref          181673 non-null  int64\n",
        " 12  delivery date        181670 non-null  datetime64[ns]\n",
        " 13  selling_price        181672 non-null  float64\n",
        " 14  delivery_time_taken  181667 non-null  float64\n",
        "dtypes: datetime64[ns](2), float64(8), int64(1), object(4)\n",
        "memory usage: 20.8+ MB\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "0\n",
        "id\t2\n",
        "item_date\t3\n",
        "quantity tons\t1\n",
        "customer\t1\n",
        "country\t28\n",
        "status\t2\n",
        "item type\t0\n",
        "application\t24\n",
        "thickness\t1\n",
        "width\t0\n",
        "material_ref\t77919\n",
        "product_ref\t0\n",
        "delivery date\t3\n",
        "selling_price\t1\n",
        "delivery_time_taken\t6\n",
        "\n",
        "dtype: int64\n",
        "\n",
        "df['id'].nunique()\n",
        "\n",
        "181671\n",
        "\n",
        "# id has unique values so either index it or drop, here dropping it.\n",
        "df.drop(['id'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# dropping material_ref column because it has huge null value it'll affect the model\n",
        "df.drop(['material_ref'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# check if there is any negative value which is logically not correct\n",
        "df.describe().T\n",
        "\n",
        "count\tmean\tmin\t25%\t50%\t75%\tmax\tstd\n",
        "item_date\t181670\t2020-11-26 22:56:58.127374080\t2020-07-02 00:00:00\t2020-09-29 00:00:00\t2020-11-30 00:00:00\t2021-02-03 00:00:00\t2021-04-01 00:00:00\tNaN\n",
        "quantity tons\t181672.0\t5874.925754\t-2000.0\t10.970298\t30.364635\t67.160612\t1000000000.0\t2349081.241674\n",
        "customer\t181672.0\t30512209.027968\t12458.0\t30196884.0\t30205242.0\t30280416.0\t2147483647.0\t24333815.584025\n",
        "country\t181645.0\t44.893022\t25.0\t26.0\t30.0\t78.0\t113.0\t24.404214\n",
        "application\t181649.0\t25.615809\t2.0\t10.0\t15.0\t41.0\t99.0\t17.754175\n",
        "thickness\t181672.0\t2.564827\t0.18\t0.7\t1.5\t3.0\t2500.0\t6.572321\n",
        "width\t181673.0\t1295.286724\t1.0\t1180.0\t1250.0\t1500.0\t2990.0\t261.631754\n",
        "product_ref\t181673.0\t473967910.724318\t611728.0\t611993.0\t640665.0\t1332077137.0\t1722207579.0\t717510064.710402\n",
        "delivery date\t181670\t2021-01-25 22:44:26.223372032\t2019-04-01 00:00:00\t2020-11-01 00:00:00\t2021-01-01 00:00:00\t2021-04-01 00:00:00\t2022-01-01 00:00:00\tNaN\n",
        "selling_price\t181672.0\t1918.035505\t-1160.0\t669.0\t812.0\t953.0\t100001015.0\t331795.642555\n",
        "delivery_time_taken\t181667.0\t64.131279\t0.0\t29.0\t61.0\t97.0\t689.0\t40.958608\n",
        "\n",
        "# converting negative values to postive\n",
        "\n",
        "df['quantity tons']=df['quantity tons'].apply(lambda x: -1*x if x<=0 else x)\n",
        "df['selling_price']=df['selling_price'].apply(lambda x: -1*x if x<=0 else x)\n",
        "\n",
        "\n",
        "# replacing null in categorical column with mode\n",
        "\n",
        "df['item_date']=df['item_date'].fillna(df['item_date'].mode()[0])\n",
        "df['status']=df['status'].fillna(df['status'].mode()[0])\n",
        "df['delivery date']=df['delivery date'].fillna(df['delivery date'].mode()[0])\n",
        "\n",
        "\n",
        "\n",
        "df.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 181673 entries, 0 to 181672\n",
        "Data columns (total 13 columns):\n",
        " #   Column               Non-Null Count   Dtype\n",
        "---  ------               --------------   -----\n",
        " 0   item_date            181673 non-null  datetime64[ns]\n",
        " 1   quantity tons        181672 non-null  float64\n",
        " 2   customer             181672 non-null  float64\n",
        " 3   country              181645 non-null  float64\n",
        " 4   status               181673 non-null  object\n",
        " 5   item type            181673 non-null  object\n",
        " 6   application          181649 non-null  float64\n",
        " 7   thickness            181672 non-null  float64\n",
        " 8   width                181673 non-null  float64\n",
        " 9   product_ref          181673 non-null  int64\n",
        " 10  delivery date        181673 non-null  datetime64[ns]\n",
        " 11  selling_price        181672 non-null  float64\n",
        " 12  delivery_time_taken  181667 non-null  float64\n",
        "dtypes: datetime64[ns](2), float64(8), int64(1), object(2)\n",
        "memory usage: 18.0+ MB\n",
        "\n",
        "# replacing null in continuous column with mean\n",
        "\n",
        "df['quantity tons'].fillna(df['quantity tons'].mean(), inplace=True)\n",
        "df['customer'].fillna(df['customer'].mean(), inplace=True)\n",
        "df['country'].fillna(df['country'].mean(), inplace=True)\n",
        "df['application'].fillna(df['application'].mean(), inplace=True)\n",
        "df['thickness'].fillna(df['thickness'].mean(), inplace=True)\n",
        "df['selling_price'].fillna(df['selling_price'].mean(), inplace=True)\n",
        "df['delivery_time_taken'].fillna(df['delivery_time_taken'].mean(), inplace=True)\n",
        "\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "0\n",
        "item_date\t0\n",
        "quantity tons\t0\n",
        "customer\t0\n",
        "country\t0\n",
        "status\t0\n",
        "item type\t0\n",
        "application\t0\n",
        "thickness\t0\n",
        "width\t0\n",
        "product_ref\t0\n",
        "delivery date\t0\n",
        "selling_price\t0\n",
        "delivery_time_taken\t0\n",
        "\n",
        "dtype: int64\n",
        "\n",
        "df.head(1)\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tdelivery_time_taken\n",
        "0\t2021-04-01\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t2021-07-01\t854.0\t91.0\n",
        "\n",
        "df['status'].unique()\n",
        "\n",
        "array(['Won', 'Draft', 'To be approved', 'Lost', 'Not lost for AM',\n",
        "       'Wonderful', 'Revised', 'Offered', 'Offerable'], dtype=object)\n",
        "\n",
        "df['item type'].unique()\n",
        "\n",
        "array(['W', 'WI', 'S', 'Others', 'PL', 'IPL', 'SLAWR'], dtype=object)\n",
        "\n",
        "# treating categorical columns by encoding, since we need status column for classifier treat them with map method\n",
        "\n",
        "df['status']=df['status'].map({'Lost':0,'Won':1,'Draft':2,'To be approved':3,'Not lost for AM':4,'Wonderful':5,'Revised':6,'Offered':7,'Offerable':8})\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "df['item type']=LabelEncoder().fit_transform(df['item type'])\n",
        "df['item type'].unique()\n",
        "\n",
        "array([5, 6, 3, 1, 2, 0, 4])\n",
        "\n",
        "df.head(1)\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tdelivery_time_taken\n",
        "0\t2021-04-01\t54.151139\t30156308.0\t28.0\t1\t5\t10.0\t2.0\t1500.0\t1670798778\t2021-07-01\t854.0\t91.0\n",
        "\n",
        "df.drop(['item_date', 'delivery date'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "df.to_csv('industrial_preprocessed.csv', index=False)\n",
        "\n",
        "\n",
        "# statistical analysis and skewness of the data\n",
        "\n",
        "\n",
        "df.corr()\n",
        "\n",
        "quantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tselling_price\tdelivery_time_taken\n",
        "quantity tons\t1.000000\t-0.000031\t-0.001530\t0.004965\t-0.002439\t-0.001956\t-0.000640\t-0.000428\t-0.001086\t-0.000010\t0.000704\n",
        "customer\t-0.000031\t1.000000\t0.000345\t0.004775\t-0.010901\t0.000004\t0.009589\t0.009203\t-0.007716\t-0.000053\t-0.001515\n",
        "country\t-0.001530\t0.000345\t1.000000\t-0.028853\t0.129940\t-0.019350\t-0.019579\t0.055293\t-0.147384\t0.002993\t-0.240438\n",
        "status\t0.004965\t0.004775\t-0.028853\t1.000000\t-0.064604\t0.085843\t-0.032165\t-0.050531\t-0.008033\t0.005463\t0.031720\n",
        "item type\t-0.002439\t-0.010901\t0.129940\t-0.064604\t1.000000\t0.169056\t-0.026079\t-0.092459\t-0.089501\t-0.005073\t-0.142578\n",
        "application\t-0.001956\t0.000004\t-0.019350\t0.085843\t0.169056\t1.000000\t-0.059468\t-0.204421\t-0.131839\t0.001462\t-0.167833\n",
        "thickness\t-0.000640\t0.009589\t-0.019579\t-0.032165\t-0.026079\t-0.059468\t1.000000\t0.161714\t0.038082\t-0.001130\t0.031179\n",
        "width\t-0.000428\t0.009203\t0.055293\t-0.050531\t-0.092459\t-0.204421\t0.161714\t1.000000\t-0.034460\t0.000583\t0.039319\n",
        "product_ref\t-0.001086\t-0.007716\t-0.147384\t-0.008033\t-0.089501\t-0.131839\t0.038082\t-0.034460\t1.000000\t0.002118\t0.161785\n",
        "selling_price\t-0.000010\t-0.000053\t0.002993\t0.005463\t-0.005073\t0.001462\t-0.001130\t0.000583\t0.002118\t1.000000\t0.000930\n",
        "delivery_time_taken\t0.000704\t-0.001515\t-0.240438\t0.031720\t-0.142578\t-0.167833\t0.031179\t0.039319\t0.161785\t0.000930\t1.000000\n",
        "\n",
        "plt.figure(figsize=(20,16),dpi=100)\n",
        "sns.heatmap(df.corr(),linewidths=0.2,annot=True,cbar=False,fmt='.2f',cmap='coolwarm')\n",
        "\n",
        "<Axes: >\n",
        "\n",
        "\n",
        "df.columns\n",
        "\n",
        "Index(['quantity tons', 'customer', 'country', 'status', 'item type',\n",
        "       'application', 'thickness', 'width', 'product_ref', 'selling_price',\n",
        "       'delivery_time_taken'],\n",
        "      dtype='object')\n",
        "\n",
        "con=['quantity tons', 'customer', 'country', 'application', 'thickness', 'width', 'product_ref','selling_price','delivery_time_taken']\n",
        "\n",
        "\n",
        "for i in ['quantity tons', 'customer', 'country', 'application', 'thickness', 'width', 'product_ref','selling_price','delivery_time_taken']:\n",
        "    print(f'skewness of {i} = {skew(df[i])}')\n",
        "\n",
        "skewness of quantity tons = 424.6873099262266\n",
        "skewness of customer = 86.984590056198\n",
        "skewness of country = 0.7536463842839621\n",
        "skewness of application = 0.7244009800031509\n",
        "skewness of thickness = 303.44512882706977\n",
        "skewness of width = 0.37459367901082125\n",
        "skewness of product_ref = 1.0152071910463223\n",
        "skewness of selling_price = 301.38559963329897\n",
        "skewness of delivery_time_taken = 0.4697225411300922\n",
        "\n",
        "def chart(column):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.subplot(1,2,1)\n",
        "  sns.histplot(data= df,x=column,kde=True,bins=30,color='red')\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  sns.boxplot(df[column])\n",
        "  plt.show\n",
        "\n",
        "\n",
        "for i in con:\n",
        "  chart(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df[\"quantity tons_modified\"]=stats.boxcox(df[\"quantity tons\"],lmbda=0)\n",
        "df[\"thickness modified\"]=stats.boxcox(df[\"thickness\"],lmbda=0)\n",
        "df[\"selling_price modified\"]=stats.boxcox(df[\"selling_price\"],lmbda=0)\n",
        "\n",
        "\n",
        "print(df['selling_price'].skew())\n",
        "\n",
        "301.3880880777512\n",
        "\n",
        "print(df['quantity tons_modified'].skew())\n",
        "print(df['thickness modified'].skew())\n",
        "print(df['selling_price modified'].skew())\n",
        "\n",
        "-0.06846424168179488\n",
        "0.351426668454226\n",
        "292.3528293105072\n",
        "\n",
        "df[\"selling_price modified\"].describe()\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py:1010: RuntimeWarning:\n",
        "\n",
        "invalid value encountered in subtract\n",
        "\n",
        "selling_price modified\n",
        "count\t1.816730e+05\n",
        "mean\t-inf\n",
        "std\tNaN\n",
        "min\t-inf\n",
        "25%\t6.505784e+00\n",
        "50%\t6.699500e+00\n",
        "75%\t6.859615e+00\n",
        "max\t1.842069e+01\n",
        "\n",
        "dtype: float64\n",
        "\n",
        "chart(\"selling_price modified\")\n",
        "\n",
        "\n",
        "\n",
        "df.drop(columns=['quantity tons','thickness','selling_price'],inplace=True)\n",
        "df.head(1)\n",
        "\n",
        "customer\tcountry\tstatus\titem type\tapplication\twidth\tproduct_ref\tdelivery_time_taken\tquantity tons_modified\tthickness modified\tselling_price modified\n",
        "0\t30156308.0\t28.0\t1\t5\t10.0\t1500.0\t1670798778\t91.0\t3.991779\t0.693147\t6.749931\n",
        "\n",
        "# charts after log transform\n",
        "for i in ['quantity tons_modified', 'customer', 'country', 'application', 'thickness modified', 'width', 'product_ref','selling_price modified','delivery_time_taken']:\n",
        "  chart(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# function to remove outliers using the IQR method\n",
        "def outliers(df,column):\n",
        "    Q1= df[column].quantile(0.25)\n",
        "    Q3= df[column].quantile(0.75)\n",
        "    IQR=Q3-Q1\n",
        "    lower_limit=Q1-1.5*IQR\n",
        "    upper_limit=Q3+1.5*IQR\n",
        "    df=df[(df[column]>=lower_limit) & (df[column]<=upper_limit)]\n",
        "    return df\n",
        "\n",
        "\n",
        "continous_column=['quantity tons_modified', 'thickness modified', 'width','selling_price modified']\n",
        "for col in continous_column:\n",
        "    df=outliers(df,col)\n",
        "\n",
        "\n",
        "df.shape\n",
        "\n",
        "(163944, 11)\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(1)\n",
        "\n",
        "customer\tcountry\tstatus\titem type\tapplication\twidth\tproduct_ref\tdelivery_time_taken\tquantity tons_modified\tthickness modified\tselling_price modified\n",
        "0\t30156308.0\t28.0\t1\t5\t10.0\t1500.0\t1670798778\t91.0\t3.991779\t0.693147\t6.749931\n",
        "\n",
        "plt.figure(figsize=(20,16),dpi=100)\n",
        "sns.heatmap(df.corr(),linewidths=0.2,annot=True,cbar=False,fmt='.2f',cmap='coolwarm')\n",
        "\n",
        "<Axes: >\n",
        "\n",
        "\n",
        "#Regression\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "x=df.drop('selling_price modified', axis=1)\n",
        "y = df['selling_price modified']\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "res=[]\n",
        "def model_check(name, model):\n",
        "  model= model.fit(x_train, y_train)\n",
        "  y_predict= model.predict(x_test)\n",
        "\n",
        "  data ={'Model_Name': name,\n",
        "         'Mean_Absolute_Error': round(mean_absolute_error(y_test, y_predict),4),\n",
        "         'Mean_Square_Error': round(mean_squared_error(y_test, y_predict),4),\n",
        "         'R2_Score': round(r2_score(y_test, y_predict), 4)}\n",
        "\n",
        "  res.append(data)\n",
        "\n",
        "\n",
        "model_check('DecisionTreeRegressor', DecisionTreeRegressor())\n",
        "\n",
        "\n",
        "model_check('LinearRegression', LinearRegression())\n",
        "\n",
        "\n",
        "model_check('RandomForestRegressor', RandomForestRegressor())\n",
        "\n",
        "\n",
        "model_check('ExtraTreesRegressor', ExtraTreesRegressor())\n",
        "\n",
        "\n",
        "model_check('GradientBoostingRegressor', GradientBoostingRegressor())\n",
        "\n",
        "\n",
        "model_check('AdaBoost Regressor', AdaBoostRegressor())\n",
        "\n",
        "\n",
        "reg_model = pd.DataFrame(res)\n",
        "reg_model\n",
        "\n",
        "Model_Name\tMean_Absolute_Error\tMean_Square_Error\tR2_Score\n",
        "0\tDecisionTreeRegressor\t0.0514\t0.0090\t0.8395\n",
        "1\tLinearRegression\t0.1505\t0.0347\t0.3829\n",
        "2\tRandomForestRegressor\t0.0439\t0.0050\t0.9115\n",
        "3\tExtraTreesRegressor\t0.0441\t0.0051\t0.9093\n",
        "4\tGradientBoostingRegressor\t0.1155\t0.0206\t0.6345\n",
        "5\tAdaBoost Regressor\t0.1381\t0.0272\t0.5169\n",
        "\n",
        "# As RandomForest have good R2 score and less MAE, MSE\n",
        "\n",
        "\n",
        "#hypertune the model\n",
        "model= RandomForestRegressor().fit(x_train, y_train)\n",
        "y_predict= model.predict(x_test)\n",
        "\n",
        "data ={'Mean_Absolute_Error': round(mean_absolute_error(y_test, y_predict),4),\n",
        "        'Mean_Square_Error': round(mean_squared_error(y_test, y_predict),4),\n",
        "        'R2_Score': round(r2_score(y_test, y_predict), 4)}\n",
        "\n",
        "data\n",
        "\n",
        "\n",
        "{'Mean_Absolute_Error': 0.0438, 'Mean_Square_Error': 0.005, 'R2_Score': 0.9118}\n",
        "\n",
        "pickle.dump(model, open('Regression_model', 'wb'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#classification model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,auc,roc_curve,confusion_matrix,classification_report\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "classification = df.copy()\n",
        "\n",
        "\n",
        "#filter the status column, we need only won and lost values\n",
        "df_classification= classification[(classification['status']==1) | (classification['status']==0)]\n",
        "df_classification.shape\n",
        "\n",
        "(137645, 11)\n",
        "\n",
        "x = df_classification.drop('status', axis=1)\n",
        "y= df_classification['status']\n",
        "\n",
        "\n",
        "x.shape, y.shape\n",
        "\n",
        "((137645, 10), (137645,))\n",
        "\n",
        "# before over sampling\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "res=[]\n",
        "def model_check(name, model):\n",
        "  model= model.fit(x_train, y_train)\n",
        "  y_predict= model.predict(x_test)\n",
        "\n",
        "  model_accuracy=accuracy_score(y_test,y_predict)\n",
        "\n",
        "  data ={'Model_Name': name,\n",
        "         'accuracy': model_accuracy}\n",
        "\n",
        "  res.append(data)\n",
        "\n",
        "\n",
        "\n",
        "model_check('Desiciontree', DecisionTreeClassifier())\n",
        "\n",
        "[{'Model_Name': 'Desiciontree', 'accuracy': 0.9471466453558066}]\n",
        "\n",
        "model_check('Randomforest', RandomForestClassifier())\n",
        "\n",
        "[{'Model_Name': 'Desiciontree', 'accuracy': 0.9471466453558066},\n",
        " {'Model_Name': 'Randomforest', 'accuracy': 0.9662174434232991}]\n",
        "\n",
        "model_check('GradientBoostingClassifier',  GradientBoostingClassifier())\n",
        "\n",
        "[{'Model_Name': 'Desiciontree', 'accuracy': 0.9471466453558066},\n",
        " {'Model_Name': 'Randomforest', 'accuracy': 0.9662174434232991},\n",
        " {'Model_Name': 'GradientBoostingClassifier', 'accuracy': 0.8349740273892986}]\n",
        "\n",
        "model_check('AdaBoostClassifier',  AdaBoostClassifier())\n",
        "\n",
        "[{'Model_Name': 'Desiciontree', 'accuracy': 0.9471466453558066},\n",
        " {'Model_Name': 'Randomforest', 'accuracy': 0.9662174434232991},\n",
        " {'Model_Name': 'GradientBoostingClassifier', 'accuracy': 0.8349740273892986},\n",
        " {'Model_Name': 'AdaBoostClassifier', 'accuracy': 0.813614733553707}]\n",
        "\n",
        "model_check('ExtraTreesClassifier',  ExtraTreesClassifier())\n",
        "\n",
        "[{'Model_Name': 'Desiciontree', 'accuracy': 0.9471466453558066},\n",
        " {'Model_Name': 'Randomforest', 'accuracy': 0.9662174434232991},\n",
        " {'Model_Name': 'GradientBoostingClassifier', 'accuracy': 0.8349740273892986},\n",
        " {'Model_Name': 'AdaBoostClassifier', 'accuracy': 0.813614733553707},\n",
        " {'Model_Name': 'ExtraTreesClassifier', 'accuracy': 0.9663990700715609}]\n",
        "\n",
        "model_df = pd.DataFrame(res)\n",
        "model_df\n",
        "\n",
        "Model_Name\taccuracy\n",
        "0\tDesiciontree\t0.947147\n",
        "1\tRandomforest\t0.966217\n",
        "2\tGradientBoostingClassifier\t0.834974\n",
        "3\tAdaBoostClassifier\t0.813615\n",
        "4\tExtraTreesClassifier\t0.966399\n",
        "\n",
        "# parameter={'n_estimators':[50,100,200],'max_depth':[10,20,30],'min_samples_split':[2,4,6],'min_samples_leaf':[1,2,3]}\n",
        "\n",
        "# grid_search=GridSearchCV(estimator=ExtraTreesClassifier(random_state=42),param_grid=parameter,cv=5, scoring=\"accuracy\",n_jobs=-1)\n",
        "\n",
        "# grid_search.fit(x_train,y_train)\n",
        "# print(\"Best Score: \", grid_search.best_score_,\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "Best Score:  0.9637382340547151 Best Parameters:  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
        "\n",
        "model= ExtraTreesClassifier(max_depth= 30, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 200).fit(x_train, y_train)\n",
        "y_predict= model.predict(x_test)\n",
        "\n",
        "\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "0.965708888808166\n",
        "\n",
        "confusion_matrix(y_test,y_predict)\n",
        "\n",
        "array([[ 5737,   568],\n",
        "       [  376, 20848]])\n",
        "\n",
        "print(classification_report(y_test,y_predict))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.94      0.91      0.92      6305\n",
        "           1       0.97      0.98      0.98     21224\n",
        "\n",
        "    accuracy                           0.97     27529\n",
        "   macro avg       0.96      0.95      0.95     27529\n",
        "weighted avg       0.97      0.97      0.97     27529\n",
        "\n",
        "\n",
        "model= RandomForestClassifier(max_depth= 20, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 150).fit(x_train, y_train)\n",
        "y_predict= model.predict(x_test)\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "0.9620037051836245\n",
        "\n",
        "confusion_matrix(y_test,y_predict)\n",
        "\n",
        "array([[ 5677,   628],\n",
        "       [  418, 20806]])\n",
        "\n",
        "print(classification_report(y_test,y_predict))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.93      0.90      0.92      6305\n",
        "           1       0.97      0.98      0.98     21224\n",
        "\n",
        "    accuracy                           0.96     27529\n",
        "   macro avg       0.95      0.94      0.95     27529\n",
        "weighted avg       0.96      0.96      0.96     27529\n",
        "\n",
        "\n",
        "# after oversampling\n",
        "\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "\n",
        "x_new,y_new=SMOTETomek().fit_resample(x,y)\n",
        "\n",
        "\n",
        "x_new.shape,y_new.shape\n",
        "\n",
        "((210140, 10), (210140,))\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_new,y_new,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "res=[]\n",
        "def model_check(name, model):\n",
        "  model= model.fit(x_train, y_train)\n",
        "  y_predict= model.predict(x_test)\n",
        "\n",
        "  model_accuracy=accuracy_score(y_test,y_predict)\n",
        "\n",
        "  data ={'Model_Name': name,\n",
        "         'accuracy': model_accuracy}\n",
        "\n",
        "  res.append(data)\n",
        "\n",
        "\n",
        "model_check('Desiciontree', DecisionTreeClassifier())\n",
        "\n",
        "\n",
        "model_check('Randomforest', RandomForestClassifier())\n",
        "\n",
        "\n",
        "model_check('GradientBoostingClassifier',  GradientBoostingClassifier())\n",
        "\n",
        "\n",
        "model_check('AdaBoostClassifier',  AdaBoostClassifier())\n",
        "\n",
        "\n",
        "model_check('ExtraTreesClassifier',  ExtraTreesClassifier())\n",
        "\n",
        "\n",
        "model_resample = pd.DataFrame(res)\n",
        "model_resample\n",
        "\n",
        "Model_Name\taccuracy\n",
        "0\tDesiciontree\t0.961692\n",
        "1\tRandomforest\t0.979680\n",
        "2\tGradientBoostingClassifier\t0.798087\n",
        "3\tAdaBoostClassifier\t0.762682\n",
        "4\tExtraTreesClassifier\t0.982369\n",
        "\n",
        "# Extratree\n",
        "model= ExtraTreesClassifier(max_depth= 30, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 200).fit(x_train, y_train)\n",
        "y_predict= model.predict(x_test)\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "0.9790853716569906\n",
        "\n",
        "confusion_matrix(y_test,y_predict)\n",
        "\n",
        "array([[20989,   171],\n",
        "       [  708, 20160]])\n",
        "\n",
        "print(classification_report(y_test,y_predict))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.99      0.98     21160\n",
        "           1       0.99      0.97      0.98     20868\n",
        "\n",
        "    accuracy                           0.98     42028\n",
        "   macro avg       0.98      0.98      0.98     42028\n",
        "weighted avg       0.98      0.98      0.98     42028\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "pickle.dump(model, open('classification_model', 'wb'))\n",
        "\n",
        "\n",
        "#Randomforest\n",
        "\n",
        "\n",
        "model= RandomForestClassifier(max_depth= 25, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 200).fit(x_train, y_train)\n",
        "y_predict= model.predict(x_test)\n",
        "accuracy_score(y_test,y_predict)\n",
        "\n",
        "0.9776339583135053\n",
        "\n",
        "confusion_matrix(y_test,y_predict)\n",
        "\n",
        "array([[20940,   220],\n",
        "       [  720, 20148]])\n",
        "\n",
        "print(classification_report(y_test,y_predict))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.99      0.98     21160\n",
        "           1       0.99      0.97      0.98     20868\n",
        "\n",
        "    accuracy                           0.98     42028\n",
        "   macro avg       0.98      0.98      0.98     42028\n",
        "weighted avg       0.98      0.98      0.98     42028\n",
        "\n",
        "\n",
        "# Extratree classifier have better precision, recall and confusion matrix"
      ]
    }
  ]
}