{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMGYwH_8r3TG"
      },
      "outputs": [],
      "source": [
        "\n",
        "Industrial copper\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from scipy import stats\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/Copper_Set.xlsx - Result 1.csv\")\n",
        "df.head(1)\n",
        "\n",
        "<ipython-input-115-55b52ccaf916>:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv(\"/content/Copper_Set.xlsx - Result 1.csv\")\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tmaterial_ref\tproduct_ref\tdelivery date\tselling_price\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\tDEQ1 S460MC\t1670798778\t20210701.0\t854.0\n",
        "\n",
        "df.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 181673 entries, 0 to 181672\n",
        "Data columns (total 14 columns):\n",
        " #   Column         Non-Null Count   Dtype\n",
        "---  ------         --------------   -----\n",
        " 0   id             181671 non-null  object\n",
        " 1   item_date      181672 non-null  float64\n",
        " 2   quantity tons  181673 non-null  object\n",
        " 3   customer       181672 non-null  float64\n",
        " 4   country        181645 non-null  float64\n",
        " 5   status         181671 non-null  object\n",
        " 6   item type      181673 non-null  object\n",
        " 7   application    181649 non-null  float64\n",
        " 8   thickness      181672 non-null  float64\n",
        " 9   width          181673 non-null  float64\n",
        " 10  material_ref   103754 non-null  object\n",
        " 11  product_ref    181673 non-null  int64\n",
        " 12  delivery date  181672 non-null  float64\n",
        " 13  selling_price  181672 non-null  float64\n",
        "dtypes: float64(8), int64(1), object(5)\n",
        "memory usage: 19.4+ MB\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "id                   2\n",
        "item_date            1\n",
        "quantity tons        0\n",
        "customer             1\n",
        "country             28\n",
        "status               2\n",
        "item type            0\n",
        "application         24\n",
        "thickness            1\n",
        "width                0\n",
        "material_ref     77919\n",
        "product_ref          0\n",
        "delivery date        1\n",
        "selling_price        1\n",
        "dtype: int64\n",
        "\n",
        "df.drop('material_ref', axis=1, inplace=True)\n",
        "df.dropna(how='any')\n",
        "\n",
        "df.head(1)\n",
        "\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\n",
        "\n",
        "df.shape\n",
        "\n",
        "(181673, 13)\n",
        "\n",
        "quant = []\n",
        "\n",
        "for i in df.itertuples():\n",
        "  if i[3] ==\"e\":\n",
        "    quant.append(i[0])\n",
        "quant\n",
        "\n",
        "[173086]\n",
        "\n",
        "df.drop(quant, inplace=True)\n",
        "\n",
        "\n",
        "df['quantity tons'] = df['quantity tons'].apply(lambda i : float(i))\n",
        "\n",
        "\n",
        "df.describe().T\n",
        "\n",
        "count\tmean\tstd\tmin\t25%\t50%\t75%\tmax\n",
        "item_date\t181671.0\t2.020459e+07\t4.551123e+03\t19950000.00\t2.020093e+07\t2.020113e+07\t2.021020e+07\t2.021040e+07\n",
        "quantity tons\t181672.0\t5.874926e+03\t2.349081e+06\t-2000.00\t1.097030e+01\t3.036464e+01\t6.716061e+01\t1.000000e+09\n",
        "customer\t181671.0\t3.051221e+07\t2.433388e+07\t12458.00\t3.019688e+07\t3.020524e+07\t3.028042e+07\t2.147484e+09\n",
        "country\t181644.0\t4.489284e+01\t2.440416e+01\t25.00\t2.600000e+01\t3.000000e+01\t7.800000e+01\t1.130000e+02\n",
        "application\t181648.0\t2.561572e+01\t1.775419e+01\t2.00\t1.000000e+01\t1.500000e+01\t4.100000e+01\t9.900000e+01\n",
        "thickness\t181671.0\t2.564839e+00\t6.572337e+00\t0.18\t7.000000e-01\t1.500000e+00\t3.000000e+00\t2.500000e+03\n",
        "width\t181672.0\t1.295288e+03\t2.616316e+02\t1.00\t1.180000e+03\t1.250000e+03\t1.500000e+03\t2.990000e+03\n",
        "product_ref\t181672.0\t4.739696e+08\t7.175117e+08\t611728.00\t6.119930e+05\t6.406650e+05\t1.332077e+09\t1.722208e+09\n",
        "delivery date\t181671.0\t2.020738e+07\t2.411065e+04\t20190401.00\t2.020110e+07\t2.021010e+07\t2.021040e+07\t3.031010e+07\n",
        "selling_price\t181671.0\t1.918042e+03\t3.317966e+05\t-1160.00\t6.690000e+02\t8.120000e+02\t9.530000e+02\t1.000010e+08\n",
        "\n",
        "df1 = df[df['quantity tons']>0]\n",
        "df1.shape\n",
        "\n",
        "(181668, 13)\n",
        "\n",
        "df2 = df[df['selling_price']<0]\n",
        "df2.shape\n",
        "\n",
        "(5, 13)\n",
        "\n",
        "df.shape\n",
        "\n",
        "(181672, 13)\n",
        "\n",
        "df.loc[df['quantity tons']<0, 'quantity tons'] = df['quantity tons'].mean()\n",
        "\n",
        "\n",
        "df.loc[df['selling_price']<0, 'selling_price'] = df['selling_price'].mean()\n",
        "df.describe().T\n",
        "\n",
        "count\tmean\tstd\tmin\t25%\t50%\t75%\tmax\n",
        "item_date\t181671.0\t2.020459e+07\t4.551123e+03\t1.995000e+07\t2.020093e+07\t2.020113e+07\t2.021020e+07\t2.021040e+07\n",
        "quantity tons\t181672.0\t5.875066e+03\t2.349081e+06\t1.000000e-05\t1.097160e+01\t3.036546e+01\t6.716700e+01\t1.000000e+09\n",
        "customer\t181671.0\t3.051221e+07\t2.433388e+07\t1.245800e+04\t3.019688e+07\t3.020524e+07\t3.028042e+07\t2.147484e+09\n",
        "country\t181644.0\t4.489284e+01\t2.440416e+01\t2.500000e+01\t2.600000e+01\t3.000000e+01\t7.800000e+01\t1.130000e+02\n",
        "application\t181648.0\t2.561572e+01\t1.775419e+01\t2.000000e+00\t1.000000e+01\t1.500000e+01\t4.100000e+01\t9.900000e+01\n",
        "thickness\t181671.0\t2.564839e+00\t6.572337e+00\t1.800000e-01\t7.000000e-01\t1.500000e+00\t3.000000e+00\t2.500000e+03\n",
        "width\t181672.0\t1.295288e+03\t2.616316e+02\t1.000000e+00\t1.180000e+03\t1.250000e+03\t1.500000e+03\t2.990000e+03\n",
        "product_ref\t181672.0\t4.739696e+08\t7.175117e+08\t6.117280e+05\t6.119930e+05\t6.406650e+05\t1.332077e+09\t1.722208e+09\n",
        "delivery date\t181671.0\t2.020738e+07\t2.411065e+04\t2.019040e+07\t2.020110e+07\t2.021010e+07\t2.021040e+07\t3.031010e+07\n",
        "selling_price\t181671.0\t1.918110e+03\t3.317966e+05\t0.000000e+00\t6.690000e+02\t8.120000e+02\t9.530000e+02\t1.000010e+08\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "id                2\n",
        "item_date         1\n",
        "quantity tons     0\n",
        "customer          1\n",
        "country          28\n",
        "status            2\n",
        "item type         0\n",
        "application      24\n",
        "thickness         1\n",
        "width             0\n",
        "product_ref       0\n",
        "delivery date     1\n",
        "selling_price     1\n",
        "dtype: int64\n",
        "\n",
        "df.shape\n",
        "\n",
        "(181672, 13)\n",
        "\n",
        "df.dropna(axis=0, inplace=True)\n",
        "df.shape\n",
        "\n",
        "(181635, 13)\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "id               0\n",
        "item_date        0\n",
        "quantity tons    0\n",
        "customer         0\n",
        "country          0\n",
        "status           0\n",
        "item type        0\n",
        "application      0\n",
        "thickness        0\n",
        "width            0\n",
        "product_ref      0\n",
        "delivery date    0\n",
        "selling_price    0\n",
        "dtype: int64\n",
        "\n",
        "df.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 181635 entries, 0 to 181672\n",
        "Data columns (total 13 columns):\n",
        " #   Column         Non-Null Count   Dtype\n",
        "---  ------         --------------   -----\n",
        " 0   id             181635 non-null  object\n",
        " 1   item_date      181635 non-null  float64\n",
        " 2   quantity tons  181635 non-null  float64\n",
        " 3   customer       181635 non-null  float64\n",
        " 4   country        181635 non-null  float64\n",
        " 5   status         181635 non-null  object\n",
        " 6   item type      181635 non-null  object\n",
        " 7   application    181635 non-null  float64\n",
        " 8   thickness      181635 non-null  float64\n",
        " 9   width          181635 non-null  float64\n",
        " 10  product_ref    181635 non-null  int64\n",
        " 11  delivery date  181635 non-null  float64\n",
        " 12  selling_price  181635 non-null  float64\n",
        "dtypes: float64(9), int64(1), object(3)\n",
        "memory usage: 19.4+ MB\n",
        "\n",
        "df['Date_difference'] = (df['delivery date'] - df['item_date'])\n",
        "df.head(1)\n",
        "\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df2 = df[df['Date_difference']<0]\n",
        "df2['Date_difference'].value_counts().sum()\n",
        "\n",
        "16107\n",
        "\n",
        "df_co = df.copy()\n",
        "\n",
        "\n",
        "df_fil = df_co[df_co['Date_difference']>0]\n",
        "df_fil.shape\n",
        "\n",
        "(165068, 14)\n",
        "\n",
        "df_fil.describe().T\n",
        "\n",
        "count\tmean\tstd\tmin\t25%\t50%\t75%\tmax\n",
        "item_date\t165068.0\t2.020480e+07\t4.588722e+03\t1.995000e+07\t2.020100e+07\t2.020120e+07\t2.021021e+07\t2.021040e+07\n",
        "quantity tons\t165068.0\t6.152332e+03\t2.461322e+06\t1.000000e-05\t1.134659e+01\t3.052059e+01\t6.691798e+01\t1.000000e+09\n",
        "customer\t165068.0\t3.023335e+07\t1.029237e+05\t1.245800e+04\t3.019689e+07\t3.020531e+07\t3.028096e+07\t3.040818e+07\n",
        "country\t165068.0\t4.532004e+01\t2.453259e+01\t2.500000e+01\t2.600000e+01\t3.000000e+01\t7.800000e+01\t1.130000e+02\n",
        "application\t165068.0\t2.495962e+01\t1.763766e+01\t2.000000e+00\t1.000000e+01\t1.500000e+01\t4.100000e+01\t9.900000e+01\n",
        "thickness\t165068.0\t2.607110e+00\t3.021227e+00\t1.800000e-01\t7.400000e-01\t1.500000e+00\t3.000000e+00\t4.000000e+02\n",
        "width\t165068.0\t1.300924e+03\t2.620794e+02\t1.000000e+00\t1.180000e+03\t1.250000e+03\t1.500000e+03\t2.990000e+03\n",
        "product_ref\t165068.0\t4.810751e+08\t7.203472e+08\t6.117280e+05\t6.283770e+05\t6.406650e+05\t1.332077e+09\t1.722208e+09\n",
        "delivery date\t165068.0\t2.020789e+07\t2.521484e+04\t2.020080e+07\t2.020120e+07\t2.021020e+07\t2.021050e+07\t3.031010e+07\n",
        "selling_price\t165068.0\t1.429542e+03\t2.461328e+05\t0.000000e+00\t6.770000e+02\t8.180000e+02\t9.580000e+02\t1.000010e+08\n",
        "Date_difference\t165068.0\t3.082992e+03\t2.519385e+04\t7.000000e+01\t1.850000e+02\t3.760000e+02\t8.976000e+03\t1.009970e+07\n",
        "\n",
        "category = ['country', 'status', 'item type', 'application', 'product_ref', 'delivery date']\n",
        "\n",
        "\n",
        "continuous = ['item_date', 'quantity tons', 'customer', 'thickness', 'width']\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "encoded=OrdinalEncoder()\n",
        "for i in df_fil.select_dtypes(include=[\"object\"]).columns:\n",
        "  df_fil[i]=encoded.fit_transform(df_fil[[i]])\n",
        "df_fil.head(1)\n",
        "\n",
        "<ipython-input-141-4a9f43cac54a>:4: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_fil[i]=encoded.fit_transform(df_fil[[i]])\n",
        "<ipython-input-141-4a9f43cac54a>:4: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_fil[i]=encoded.fit_transform(df_fil[[i]])\n",
        "<ipython-input-141-4a9f43cac54a>:4: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_fil[i]=encoded.fit_transform(df_fil[[i]])\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\t152282.0\t20210401.0\t54.151139\t30156308.0\t28.0\t7.0\t5.0\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df_fil.drop('id', axis=1, inplace=True)\n",
        "df_fil.head(1)\n",
        "\n",
        "<ipython-input-142-fdf5ca2d2109>:1: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_fil.drop('id', axis=1, inplace=True)\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\t20210401.0\t54.151139\t30156308.0\t28.0\t7.0\t5.0\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df_fil.corr()\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "item_date\t1.000000\t-0.002194\t0.001837\t-0.020606\t0.076236\t0.069597\t0.003948\t-0.008913\t0.008216\t0.032781\t0.095565\t0.003357\t-0.086492\n",
        "quantity tons\t-0.002194\t1.000000\t-0.000659\t-0.001543\t-0.002762\t-0.002645\t-0.002083\t-0.001430\t-0.000478\t-0.001079\t-0.000672\t-0.000009\t-0.000273\n",
        "customer\t0.001837\t-0.000659\t1.000000\t0.081348\t-0.025631\t-0.083192\t0.010473\t0.079997\t0.046147\t-0.034176\t0.001637\t-0.000376\t0.001304\n",
        "country\t-0.020606\t-0.001543\t0.081348\t1.000000\t0.114586\t0.144586\t-0.012177\t-0.045656\t0.046705\t-0.151469\t-0.018798\t-0.001862\t-0.015061\n",
        "status\t0.076236\t-0.002762\t-0.025631\t0.114586\t1.000000\t0.254169\t0.117895\t-0.115313\t-0.087054\t-0.068245\t0.006076\t-0.002623\t-0.007804\n",
        "item type\t0.069597\t-0.002645\t-0.083192\t0.144586\t0.254169\t1.000000\t0.150917\t-0.050054\t-0.084231\t-0.092540\t0.005194\t-0.004896\t-0.007477\n",
        "application\t0.003948\t-0.002083\t0.010473\t-0.012177\t0.117895\t0.150917\t1.000000\t-0.131949\t-0.198500\t-0.136197\t-0.005705\t-0.001970\t-0.006429\n",
        "thickness\t-0.008913\t-0.001430\t0.079997\t-0.045656\t-0.115313\t-0.050054\t-0.131949\t1.000000\t0.364002\t0.066206\t-0.001136\t-0.001875\t0.000487\n",
        "width\t0.008216\t-0.000478\t0.046147\t0.046705\t-0.087054\t-0.084231\t-0.198500\t0.364002\t1.000000\t-0.032381\t-0.003554\t0.001204\t-0.005054\n",
        "product_ref\t0.032781\t-0.001079\t-0.034176\t-0.151469\t-0.068245\t-0.092540\t-0.136197\t0.066206\t-0.032381\t1.000000\t0.011350\t-0.001133\t0.005389\n",
        "delivery date\t0.095565\t-0.000672\t0.001637\t-0.018798\t0.006076\t0.005194\t-0.005705\t-0.001136\t-0.003554\t0.011350\t1.000000\t0.000322\t0.983427\n",
        "selling_price\t0.003357\t-0.000009\t-0.000376\t-0.001862\t-0.002623\t-0.004896\t-0.001970\t-0.001875\t0.001204\t-0.001133\t0.000322\t1.000000\t-0.000289\n",
        "Date_difference\t-0.086492\t-0.000273\t0.001304\t-0.015061\t-0.007804\t-0.007477\t-0.006429\t0.000487\t-0.005054\t0.005389\t0.983427\t-0.000289\t1.000000\n",
        "\n",
        "plt.figure(figsize=(20,16),dpi=100)\n",
        "sns.heatmap(df_fil.corr(),linewidths=0.2,annot=True,cbar=False,fmt='.2f',cmap='coolwarm')\n",
        "\n",
        "<Axes: >\n",
        "\n",
        "\n",
        "def two_sample(d1,d2): #continuous vs continuous\n",
        "  m=[0,0]\n",
        "  for i in range(31):\n",
        "      sample1 = d1.sample(frac=0.03)\n",
        "      sample2 = d2.sample(frac=0.04)\n",
        "      t_test , p_value = stats.ttest_ind(sample1,sample2) #two_sample t-test\n",
        "      if p_value < 0.03: #setting critical point , level of significance = 0.03\n",
        "          m[1]+=1\n",
        "      else:\n",
        "          m[0]+=1\n",
        "\n",
        "  if m[0]>m[1]:\n",
        "    #print(\"H0 accept null hypothesis, Ha rejects alternate hypothesis, dependent samples , data is normally distributed\")\n",
        "    return True\n",
        "  elif m[0]\n",
        "\n",
        " #category vs category\n",
        "def Chi_square1(d1,d2):\n",
        "  return True if stats.chi2_contingency(pd.crosstab(d1,d2).values)[1] < 0.03 else False\n",
        "\n",
        "\n",
        "def annova1(c1,c2): #category vs continuous\n",
        "  group=df[c1].unique()\n",
        "  data={}\n",
        "  for i in group:\n",
        "    data[i]=df_fil[c2][df_fil[c1]==i]\n",
        "  return False if stats.f_oneway(*[i for i in data.values()])[1] < 0.05 else True\n",
        "\n",
        "\n",
        "#hypothesis testing\n",
        "hypo={}\n",
        "for i in df_fil.columns:\n",
        "  hypo[i]={}\n",
        "  for j in df_fil.columns:\n",
        "    if i=='selling_price' or j=='selling_price':\n",
        "      continue\n",
        "    elif i in continuous and j in continuous:\n",
        "      result=two_sample(df_fil[i],df_fil[j])\n",
        "    elif i in category and j in category:\n",
        "      result=Chi_square1(df_fil[i],df_fil[j])\n",
        "    elif i in category and j in continuous:\n",
        "      result=annova1(i,j)\n",
        "    elif i in continuous and j in category:\n",
        "      result=annova1(j,i)\n",
        "    if result:\n",
        "      hypo[i][j]=1\n",
        "    else:\n",
        "      hypo[i][j]=0\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4133: DegenerateDataWarning: at least one input has length 0\n",
        "  warnings.warn(stats.DegenerateDataWarning('at least one input '\n",
        "\n",
        "hypo_df = pd.DataFrame(hypo)\n",
        "hypo_df.drop(\"selling_price\", axis=1, inplace=True)\n",
        "hypo_df\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tDate_difference\n",
        "item_date\t1\t0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t1\n",
        "quantity tons\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t1\n",
        "customer\t0\t0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t1\n",
        "country\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t1\n",
        "status\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n",
        "item type\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n",
        "application\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t1\n",
        "thickness\t0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\t1\n",
        "width\t0\t0\t0\t0\t1\t1\t0\t0\t1\t1\t1\t1\n",
        "product_ref\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n",
        "delivery date\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n",
        "Date_difference\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n",
        "\n",
        "#Regression\n",
        "\n",
        "\n",
        "x = df_fil.drop(\"selling_price\", axis=1)\n",
        "y = df_fil['selling_price']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "\n",
        "\n",
        "#DecisionTree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model = DecisionTreeRegressor().fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_predict=model.predict(x_test)\n",
        "\n",
        "\n",
        "MAE=mean_absolute_error(y_test,y_predict)\n",
        "MAE\n",
        "\n",
        "31.046156390980517\n",
        "\n",
        "MSE=mean_squared_error(y_test,y_predict)\n",
        "MSE\n",
        "\n",
        "8224.114125499473\n",
        "\n",
        "RMSE=np.sqrt(MSE)\n",
        "RMSE\n",
        "\n",
        "90.68690162035239\n",
        "\n",
        "r2=r2_score(y_test,y_predict)\n",
        "r2\n",
        "\n",
        "0.8507809869021175\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "#pickle.dump(model, open('model_dt(0.865)', 'wb'))\n",
        "\n",
        "\n",
        "test_data = np.array([[200401.0, 55, 30156310, 30, 8, 4, 10, 3, 1600, 1670798779, 20210710, 250]])\n",
        "\n",
        "\n",
        "#file=r\"/content/model_dt(0.865)\"\n",
        "\n",
        "\n",
        "#x.head(1)\n",
        "\n",
        "\n",
        "#test = pickle.load(open(file, 'rb'))\n",
        "\n",
        "\n",
        "#test.predict(test_data)\n",
        "\n",
        "\n",
        "#RandomForest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "modelRF = RandomForestRegressor().fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_predictRF = modelRF.predict(x_test)\n",
        "\n",
        "\n",
        "MAE_RF=mean_absolute_error(y_test,y_predictRF)\n",
        "MAE_RF\n",
        "\n",
        "843.6882067719207\n",
        "\n",
        "MSE_RF=mean_squared_error(y_test,y_predictRF)\n",
        "MSE_RF\n",
        "\n",
        "9359678567.55826\n",
        "\n",
        "RMSE_RF=np.sqrt(MSE_RF)\n",
        "RMSE_RF\n",
        "\n",
        "96745.43176583719\n",
        "\n",
        "r2_RF=r2_score(y_test,y_predictRF)\n",
        "r2_RF\n",
        "\n",
        "-169821.7891116023\n",
        "\n",
        "#GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "modelGB= GradientBoostingRegressor().fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_predictGB = modelGB.predict(x_test)\n",
        "\n",
        "\n",
        "MAE_GB=mean_absolute_error(y_test,y_predictGB)\n",
        "MAE_GB\n",
        "\n",
        "4111.660628087466\n",
        "\n",
        "MSE_GB=mean_squared_error(y_test,y_predictGB)\n",
        "MSE_GB\n",
        "\n",
        "214749911049.31842\n",
        "\n",
        "RMSE_GB=np.sqrt(MSE_GB)\n",
        "RMSE_GB\n",
        "\n",
        "463411.16845552874\n",
        "\n",
        "r2_GB=r2_score(y_test,y_predictGB)\n",
        "r2_GB\n",
        "\n",
        "-3896439.309635318\n",
        "\n",
        "#Adaboost\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "modelAB= AdaBoostRegressor().fit(x_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_predictAB = modelAB.predict(x_test)\n",
        "\n",
        "\n",
        "MAE_AB=mean_absolute_error(y_test,y_predictAB)\n",
        "MAE_AB\n",
        "\n",
        "104.74195202343162\n",
        "\n",
        "MSE_AB=mean_squared_error(y_test,y_predictAB)\n",
        "MSE_AB\n",
        "\n",
        "26902.49586274631\n",
        "\n",
        "RMSE_AB=np.sqrt(MSE_AB)\n",
        "RMSE_AB\n",
        "\n",
        "164.0198032639544\n",
        "\n",
        "r2_AB=r2_score(y_test,y_predictAB)\n",
        "r2_AB\n",
        "\n",
        "0.5118788697177681\n",
        "\n",
        "!pip install xgboost\n",
        "\n",
        "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
        "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
        "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
        "\n",
        "#xg boost\n",
        "import xgboost as xgb\n",
        "modelxg = xgb.XGBRegressor().fit(x_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_predictxg = modelxg.predict(x_test)\n",
        "\n",
        "\n",
        "mae_xg = mean_absolute_error(y_test, y_predictxg)\n",
        "mae_xg\n",
        "\n",
        "35.06127691314755\n",
        "\n",
        "mse_xg = mean_squared_error(y_test, y_predictxg)\n",
        "mse_xg\n",
        "\n",
        "7545.969588973074\n",
        "\n",
        "rmse_xg = np.sqrt(mse_xg)\n",
        "rmse_xg\n",
        "\n",
        "86.86754047958924\n",
        "\n",
        "r2_xg = r2_score(y_test, y_predictxg)\n",
        "r2_xg\n",
        "\n",
        "0.8630852979724657\n",
        "\n",
        "#pickle.dump(modelxg, open('model_xgboost(0.943)', 'wb'))\n",
        "\n",
        "\n",
        "#testxg = pickle.load(open('/content/model_xgboost(0.943)', 'rb'))\n",
        "\n",
        "\n",
        "#testxg.predict(test_data)\n",
        "\n",
        "\n",
        "#decision tree r2 of 0.865 and xg boost r2 of 0.943 worked well for this data\n",
        "\n",
        "\n",
        "#classifier\n",
        "\n",
        "\n",
        "df.head(1)\n",
        "\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df_fil2 = df_co[df_co['Date_difference']>0]\n",
        "df_fil2.head(1)\n",
        "\n",
        "id\titem_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\tEC06F063-9DF0-440C-8764-0B0C05A4F6AE\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df_fil2.drop('id', axis=1, inplace=True)\n",
        "df_fil2.head(1)\n",
        "\n",
        "<ipython-input-199-45054aeb7609>:1: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_fil2.drop('id', axis=1, inplace=True)\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df_cl = df_fil2[df_fil2['status'].isin(['Won', 'Draft'])]\n",
        "df_cl.shape\n",
        "\n",
        "(104305, 13)\n",
        "\n",
        "df_cl['status'].unique()\n",
        "\n",
        "array(['Won', 'Draft'], dtype=object)\n",
        "\n",
        "df_cl.reset_index(drop=True)\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.00\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "1\t20210401.0\t3.522613\t30209509.0\t30.0\tDraft\tW\t41.0\t0.38\t1125.0\t611993\t20210701.0\t18.0\t300.0\n",
        "2\t20210401.0\t69.071853\t30341428.0\t38.0\tWon\tS\t10.0\t0.60\t1275.0\t1668701376\t20210701.0\t1363.0\t300.0\n",
        "3\t20210401.0\t9.175770\t30209509.0\t30.0\tDraft\tW\t41.0\t0.38\t1125.0\t611993\t20210701.0\t17.0\t300.0\n",
        "4\t20210401.0\t27.512545\t30165529.0\t78.0\tWon\tW\t10.0\t0.75\t1250.0\t164141591\t20210701.0\t1098.0\t300.0\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "104300\t20200702.0\t34.992516\t30201370.0\t84.0\tWon\tS\t15.0\t5.00\t1500.0\t1671863738\t20200901.0\t608.0\t199.0\n",
        "104301\t20200702.0\t52.791503\t30201370.0\t84.0\tWon\tS\t15.0\t4.00\t1500.0\t1671863738\t20200901.0\t615.0\t199.0\n",
        "104302\t20200702.0\t52.514106\t30201370.0\t84.0\tWon\tS\t15.0\t6.00\t1500.0\t1671863738\t20200901.0\t612.0\t199.0\n",
        "104303\t20200702.0\t33.978646\t30201370.0\t84.0\tWon\tS\t15.0\t8.00\t1500.0\t1671863738\t20200901.0\t627.0\t199.0\n",
        "104304\t20200702.0\t83.434376\t30197813.0\t27.0\tWon\tS\t10.0\t1.50\t1500.0\t640665\t20200801.0\t493.0\t99.0\n",
        "104305 rows Ã— 13 columns\n",
        "\n",
        "\n",
        "df_cl.head(1)\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\t20210401.0\t54.151139\t30156308.0\t28.0\tWon\tW\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "for i in df_cl.select_dtypes(include=[\"object\"]).columns:\n",
        "  df_cl[i]=encoded.fit_transform(df_cl[[i]])\n",
        "df_cl.head(1)\n",
        "\n",
        "<ipython-input-204-f02ba180d6b4>:2: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_cl[i]=encoded.fit_transform(df_cl[[i]])\n",
        "<ipython-input-204-f02ba180d6b4>:2: SettingWithCopyWarning:\n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
        "  df_cl[i]=encoded.fit_transform(df_cl[[i]])\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "0\t20210401.0\t54.151139\t30156308.0\t28.0\t1.0\t5.0\t10.0\t2.0\t1500.0\t1670798778\t20210701.0\t854.0\t300.0\n",
        "\n",
        "df_cl.corr()\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "item_date\t1.000000\t-0.006467\t0.001194\t-0.044908\t-0.053896\t0.045284\t-0.007307\t0.006305\t0.027684\t0.044454\t0.568302\t0.441795\t-0.561057\n",
        "quantity tons\t-0.006467\t1.000000\t0.013062\t-0.034798\t0.012852\t-0.121716\t0.016276\t0.007457\t0.007143\t0.008970\t0.009199\t-0.031776\t0.016580\n",
        "customer\t0.001194\t0.013062\t1.000000\t0.092189\t0.032843\t-0.145783\t0.029989\t0.132774\t0.060759\t-0.045703\t0.005777\t0.000904\t0.004459\n",
        "country\t-0.044908\t-0.034798\t0.092189\t1.000000\t-0.013489\t0.093611\t-0.053445\t-0.034632\t0.057434\t-0.168615\t-0.116936\t-0.031747\t-0.066769\n",
        "status\t-0.053896\t0.012852\t0.032843\t-0.013489\t1.000000\t0.024765\t-0.044766\t0.036939\t0.006225\t0.046899\t-0.038874\t0.538921\t0.021945\n",
        "item type\t0.045284\t-0.121716\t-0.145783\t0.093611\t0.024765\t1.000000\t0.124990\t-0.039955\t-0.075800\t-0.080550\t0.029905\t0.111341\t-0.021211\n",
        "application\t-0.007307\t0.016276\t0.029989\t-0.053445\t-0.044766\t0.124990\t1.000000\t-0.103733\t-0.203700\t-0.113361\t-0.000325\t0.100341\t0.007951\n",
        "thickness\t0.006305\t0.007457\t0.132774\t-0.034632\t0.036939\t-0.039955\t-0.103733\t1.000000\t0.329282\t0.076479\t0.016280\t-0.228363\t0.009235\n",
        "width\t0.027684\t0.007143\t0.060759\t0.057434\t0.006225\t-0.075800\t-0.203700\t0.329282\t1.000000\t-0.040470\t-0.011753\t-0.140040\t-0.043184\n",
        "product_ref\t0.044454\t0.008970\t-0.045703\t-0.168615\t0.046899\t-0.080550\t-0.113361\t0.076479\t-0.040470\t1.000000\t0.083316\t-0.054031\t0.033461\n",
        "delivery date\t0.568302\t0.009199\t0.005777\t-0.116936\t-0.038874\t0.029905\t-0.000325\t0.016280\t-0.011753\t0.083316\t1.000000\t0.379668\t0.362261\n",
        "selling_price\t0.441795\t-0.031776\t0.000904\t-0.031747\t0.538921\t0.111341\t0.100341\t-0.228363\t-0.140040\t-0.054031\t0.379668\t1.000000\t-0.118502\n",
        "Date_difference\t-0.561057\t0.016580\t0.004459\t-0.066769\t0.021945\t-0.021211\t0.007951\t0.009235\t-0.043184\t0.033461\t0.362261\t-0.118502\t1.000000\n",
        "\n",
        "plt.figure(figsize=(20,16),dpi=100)\n",
        "sns.heatmap(df_fil.corr(),linewidths=0.2,annot=True,cbar=False,fmt='.2f',cmap='coolwarm')\n",
        "\n",
        "<Axes: >\n",
        "\n",
        "\n",
        "continuous = ['quantity tons', 'customer', 'thickness', 'width', 'selling_price']\n",
        "\n",
        "\n",
        "def annova1(c1,c2): #category vs continuous\n",
        "  group=df_cl[c1].unique()\n",
        "  data={}\n",
        "  for i in group:\n",
        "    data[i]=df_cl[c2][df_cl[c1]==i]\n",
        "  return False if stats.f_oneway(*[i for i in data.values()])[1] < 0.05 else True\n",
        "\n",
        "\n",
        "#hypothesis testing\n",
        "hypo={}\n",
        "for i in df_cl.columns:\n",
        "  hypo[i]={}\n",
        "  for j in df_cl.columns:\n",
        "    if i=='status' or j=='status':\n",
        "      continue\n",
        "    elif i in continuous and j in continuous:\n",
        "      result=two_sample(df_cl[i],df_cl[j])\n",
        "    elif i in category and j in category:\n",
        "      result=Chi_square1(df_cl[i],df_cl[j])\n",
        "    elif i in category and j in continuous:\n",
        "      result=annova1(i,j)\n",
        "    elif i in continuous and j in category:\n",
        "      result=annova1(j,i)\n",
        "    if result:\n",
        "      hypo[i][j]=1\n",
        "    else:\n",
        "      hypo[i][j]=0\n",
        "\n",
        "\n",
        "hypo_df = pd.DataFrame(hypo)\n",
        "hypo_df\n",
        "\n",
        "item_date\tquantity tons\tcustomer\tcountry\tstatus\titem type\tapplication\tthickness\twidth\tproduct_ref\tdelivery date\tselling_price\tDate_difference\n",
        "item_date\t1\t1\t0\t0\tNaN\t0\t0\t0\t0\t0\t0\t0\t1\n",
        "quantity tons\t1\t1\t0\t0\tNaN\t0\t0\t0\t0\t0\t0\t0\t1\n",
        "customer\t1\t0\t1\t0\tNaN\t0\t0\t0\t0\t0\t0\t0\t1\n",
        "country\t1\t0\t0\t1\tNaN\t1\t1\t0\t0\t1\t1\t0\t1\n",
        "item type\t1\t0\t0\t1\tNaN\t1\t1\t0\t0\t1\t1\t0\t1\n",
        "application\t1\t0\t0\t1\tNaN\t1\t1\t0\t0\t1\t1\t0\t1\n",
        "thickness\t1\t0\t0\t0\tNaN\t0\t0\t1\t0\t0\t0\t0\t1\n",
        "width\t1\t0\t0\t0\tNaN\t0\t0\t0\t1\t0\t0\t0\t1\n",
        "product_ref\t1\t0\t0\t1\tNaN\t1\t1\t0\t0\t1\t1\t0\t1\n",
        "delivery date\t1\t0\t0\t1\tNaN\t1\t1\t0\t0\t1\t1\t0\t1\n",
        "selling_price\t1\t0\t0\t0\tNaN\t0\t0\t0\t0\t0\t0\t1\t1\n",
        "Date_difference\t1\t0\t0\t0\tNaN\t0\t0\t0\t0\t0\t0\t1\t1\n",
        "\n",
        "x = df_cl.drop('status', axis=1)\n",
        "y = df_cl['status']\n",
        "\n",
        "\n",
        "x.shape, y.shape\n",
        "\n",
        "((104305, 12), (104305,))\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "sampler1=SMOTETomek()\n",
        "x_new,y_new=sampler1.fit_resample(x,y)\n",
        "x_new.shape,y_new.shape\n",
        "\n",
        "((203156, 12), (203156,))\n",
        "\n",
        "#model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x_new,y_new,test_size=0.2)\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "model=DecisionTreeClassifier(max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=2).fit(x_train,y_train)\n",
        "\n",
        "\n",
        "y_predict=model.predict(x_test)\n",
        "\n",
        "\n",
        "accuracy=accuracy_score(y_test,y_predict)\n",
        "accuracy\n",
        "\n",
        "0.9999753888560741\n",
        "\n",
        "print(classification_report(y_test,y_predict))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       1.00      1.00      1.00     20290\n",
        "         1.0       1.00      1.00      1.00     20342\n",
        "\n",
        "    accuracy                           1.00     40632\n",
        "   macro avg       1.00      1.00      1.00     40632\n",
        "weighted avg       1.00      1.00      1.00     40632\n",
        "\n",
        "\n",
        "confusion=confusion_matrix(y_test,y_predict)\n",
        "confusion\n",
        "\n",
        "array([[20290,     0],\n",
        "       [    1, 20341]])\n",
        "\n",
        "#RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_RF = RandomForestClassifier(max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=2).fit(x_train, y_train)\n",
        "y_predict_RF = model_RF.predict(x_test)\n",
        "\n",
        "\n",
        "accuracy_rf=accuracy_score(y_test,y_predict_RF)\n",
        "accuracy_rf\n",
        "\n",
        "0.9999753888560741\n",
        "\n",
        "confusion=confusion_matrix(y_test,y_predict_RF)\n",
        "confusion\n",
        "\n",
        "array([[20290,     0],\n",
        "       [    1, 20341]])\n",
        "\n",
        "print(classification_report(y_test,y_predict_RF))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       1.00      1.00      1.00     20290\n",
        "         1.0       1.00      1.00      1.00     20342\n",
        "\n",
        "    accuracy                           1.00     40632\n",
        "   macro avg       1.00      1.00      1.00     40632\n",
        "weighted avg       1.00      1.00      1.00     40632\n",
        "\n",
        "\n",
        "#grid search\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and parameter grids\n",
        "models = {\n",
        "    'RandomForest': (RandomForestClassifier(), {\n",
        "        'n_estimators': [10, 50, 100],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "    }),\n",
        "    'GradientBoosting': (GradientBoostingClassifier(), {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7],\n",
        "    }),\n",
        "    'SVM': (SVC(), {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto'],\n",
        "    })\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for each model\n",
        "results = {}\n",
        "\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    print(f\"Performing GridSearchCV for {model_name}\")\n",
        "\n",
        "    # Set up GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "    # Fit model\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store results\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[model_name] = {\n",
        "        'Best Parameters': best_params,\n",
        "        'Best Model': best_model,\n",
        "        'Test Accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    print(f\"Best Parameters for {model_name}: {best_params}\")\n",
        "    print(f\"Test Accuracy for {model_name}: {accuracy:.2f}\\n\")\n",
        "\n",
        "# Review results\n",
        "for model_name, result in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Best Parameters: {result['Best Parameters']}\")\n",
        "    print(f\"  Test Accuracy: {result['Test Accuracy']:.2f}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "ValueError                                Traceback (most recent call last)\n",
        "<ipython-input-226-7a7847b5b5a9> in <cell line: 14>()\n",
        "     12\n",
        "     13 # Split into train and test sets\n",
        "---> 14 X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "     15\n",
        "     16 # Define models and parameter grids\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py in train_test_split(test_size, train_size, random_state, shuffle, stratify, *arrays)\n",
        "   2557         raise ValueError(\"At least one array required as input\")\n",
        "   2558\n",
        "-> 2559     arrays = indexable(*arrays)\n",
        "   2560\n",
        "   2561     n_samples = _num_samples(arrays[0])\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py in indexable(*iterables)\n",
        "    441\n",
        "    442     result = [_make_indexable(X) for X in iterables]\n",
        "--> 443     check_consistent_length(*result)\n",
        "    444     return result\n",
        "    445\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py in check_consistent_length(*arrays)\n",
        "    395     uniques = np.unique(lengths)\n",
        "    396     if len(uniques) > 1:\n",
        "--> 397         raise ValueError(\n",
        "    398             \"Found input variables with inconsistent numbers of samples: %r\"\n",
        "    399             % [int(l) for l in lengths]\n",
        "\n",
        "ValueError: Found input variables with inconsistent numbers of samples: [104305, 150]\n",
        "\n",
        "#after over sampling\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_new, y_new, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and parameter grids\n",
        "models = {\n",
        "    'RandomForest': (RandomForestClassifier(), {\n",
        "        'n_estimators': [10, 50, 100],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "    }),\n",
        "    'GradientBoosting': (GradientBoostingClassifier(), {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7],\n",
        "    }),\n",
        "    'SVM': (SVC(), {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto'],\n",
        "    })\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for each model\n",
        "results = {}\n",
        "\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    print(f\"Performing GridSearchCV for {model_name}\")\n",
        "\n",
        "    # Set up GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "    # Fit model\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store results\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[model_name] = {\n",
        "        'Best Parameters': best_params,\n",
        "        'Best Model': best_model,\n",
        "        'Test Accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    print(f\"Best Parameters for {model_name}: {best_params}\")\n",
        "    print(f\"Test Accuracy for {model_name}: {accuracy:.2f}\\n\")\n",
        "\n",
        "# Review results\n",
        "for model_name, result in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Best Parameters: {result['Best Parameters']}\")\n",
        "    print(f\"  Test Accuracy: {result['Test Accuracy']:.2f}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "Performing GridSearchCV for RandomForest\n",
        "Fitting 5 folds for each of 36 candidates, totalling 180 fits"
      ]
    }
  ]
}